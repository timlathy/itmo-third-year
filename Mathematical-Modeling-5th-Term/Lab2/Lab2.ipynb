{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --user --quiet ciw\n",
    "import ciw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, ClassVar\n",
    "from tqdm import tqdm\n",
    "\n",
    "@dataclass\n",
    "class Distribution:\n",
    "    kind: str\n",
    "    mean: float\n",
    "    d: ClassVar[ciw.dists.Distribution]\n",
    "\n",
    "@dataclass\n",
    "class Model:\n",
    "    num_servers: int\n",
    "    queue_capacity: int\n",
    "    arrival_dist: Distribution\n",
    "    service_dist: Distribution\n",
    "\n",
    "@dataclass\n",
    "class SimResult:\n",
    "    model: ClassVar[Model]\n",
    "    task_count: int\n",
    "    utilization: float\n",
    "    loss_probability: float\n",
    "    mean_wait_time: float\n",
    "    mean_residence_time: float\n",
    "    \n",
    "    def __init__(self, model: Model, sim: ciw.Simulation):\n",
    "        self.model = model\n",
    "        self.utilization = sim.transitive_nodes[0].server_utilisation\n",
    "        \n",
    "        tasks = sim.get_all_records()\n",
    "        self.task_count = len(tasks)\n",
    "        self.loss_probability = len(sim.rejection_dict[1][0]) / self.task_count\n",
    "        self.mean_wait_time = sum(t.waiting_time for t in tasks) / self.task_count\n",
    "        self.mean_residence_time = sum(t.waiting_time + t.service_time for t in tasks) / self.task_count\n",
    "\n",
    "def simulate(model: Model, task_measures: List[int]) -> List[SimResult]:\n",
    "    sim = ciw.Simulation(ciw.create_network(\n",
    "        arrival_distributions=[model.arrival_dist.d],\n",
    "        service_distributions=[model.service_dist.d],\n",
    "        number_of_servers=[model.num_servers],\n",
    "        queue_capacities=[model.queue_capacity]\n",
    "    ))\n",
    "    results = []\n",
    "    for task_count in tqdm(task_measures):\n",
    "        sim.simulate_until_max_customers(task_count, method='Finish')\n",
    "        results.append(SimResult(model, sim))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    " \n",
    "@dataclass\n",
    "class DExp(Distribution):\n",
    "    def __init__(self, rate):\n",
    "        self.kind = 'Exponential'\n",
    "        self.mean = 1 / rate\n",
    "        self.d = ciw.dists.Exponential(rate)\n",
    "\n",
    "@dataclass\n",
    "class DUniform(Distribution):\n",
    "    def __init__(self, a, b):\n",
    "        self.kind = 'Uniform'\n",
    "        self.mean = (a + b) / 2\n",
    "        self.d = ciw.dists.Uniform(a, b)\n",
    "\n",
    "@dataclass\n",
    "class DHypoexp2(Distribution):\n",
    "    def __init__(self, rate1, rate2):\n",
    "        self.kind = 'Hypoexponential'\n",
    "        self.mean = 1 / rate1 + 1 / rate2\n",
    "        self.d = ciw.dists.Exponential(rate1) + ciw.dists.Exponential(rate2)\n",
    "\n",
    "@dataclass\n",
    "class DErlang2(Distribution):\n",
    "    def __init__(self, rate):\n",
    "        self.kind = 'Erlang'\n",
    "        self.mean = 1 / rate + 1 / rate\n",
    "        self.d = ciw.dists.Exponential(rate) + ciw.dists.Exponential(rate)\n",
    "\n",
    "@dataclass\n",
    "class DHyperexp(Distribution):\n",
    "    def __init__(self, qq, tt_1, tt_2):\n",
    "        self.kind = 'Hyperexponential'\n",
    "        self.mean = qq / tt_1 + qq / tt_2\n",
    "        if uniform(0, 1) < qq:\n",
    "            self.d = ciw.dists.Exponential(tt_1);\n",
    "        else:\n",
    "            self.d = ciw.dists.Exponential(tt_2);\n",
    "\n",
    "@dataclass\n",
    "class DTrace(Distribution):\n",
    "    def __init__(self):\n",
    "        with open('trace.txt', 'r') as f:\n",
    "            trace = [float(v) for v in f.read().splitlines()]\n",
    " \n",
    "        self.kind = 'Trace'\n",
    "        self.mean = sum(trace) / len(trace)\n",
    "        self.d = ciw.dists.Sequential(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #3.2.1\n",
    "    #varying utilization\n",
    "    #utilization = 0.1\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 50), service_dist=DExp(1 / 10)),\n",
    "    #utilization = 0.5\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    #utilization = 0.9\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 10), service_dist=DExp(1 / 18)),\n",
    "   \n",
    "    #3.2.2\n",
    "    #vary lambda\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    #decrease\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 15), service_dist=DExp(1 / 30)),\n",
    "    #increase\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 45), service_dist=DExp(1 / 30)),\n",
    "   \n",
    "    #vary mu\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    #decrease\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 15)),\n",
    "    #increase\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 45)),\n",
    " \n",
    "    #try different service distributions\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DUniform(1, 10)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DErlang2(1 / 9)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DHyperexp(1 / 30, 1 / 30, 1 / 30)),\n",
    "   \n",
    "    #try different arrival distributions\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DTrace(), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DHypoexp2(1 / 8.55, 1 / 1.3), service_dist=DExp(1 / 30)),\n",
    "   \n",
    "    #3.2.3\n",
    "    #varying queue capacity to determine at which point can we treat the model as a model with infinite queue\n",
    "    #utilization = 0.5\n",
    "    #loss probability is 0 at 14 (but the results can vary actually...) if running 100k tasks\n",
    "    Model(num_servers=2, queue_capacity=8, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=2, queue_capacity=12, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=2, queue_capacity=14, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=2, queue_capacity=16, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "   \n",
    "    #utilization 0.9\n",
    "    #loss probability is 0 at 70 (results can vary greatly) if running 100k tasks\n",
    "    Model(num_servers=2, queue_capacity=55, arrival_dist=DExp(1 / 10), service_dist=DExp(1 / 18)),\n",
    "    Model(num_servers=2, queue_capacity=60, arrival_dist=DExp(1 / 10), service_dist=DExp(1 / 18)),\n",
    "    Model(num_servers=2, queue_capacity=65, arrival_dist=DExp(1 / 10), service_dist=DExp(1 / 18)),\n",
    "    Model(num_servers=2, queue_capacity=70, arrival_dist=DExp(1 / 10), service_dist=DExp(1 / 18)),\n",
    "    Model(num_servers=2, queue_capacity=75, arrival_dist=DExp(1 / 10), service_dist=DExp(1 / 18)),\n",
    "   \n",
    "    #3.2.4\n",
    "    #varying servers count (1,2,3) and utilization (0.1, 0.5, 0.9)\n",
    "    #and varying lambda & mu to keep utilization and load constant\n",
    "    #utilization = 0.1\n",
    "    Model(num_servers=1, queue_capacity=10, arrival_dist=DExp(1 / 200), service_dist=DExp(1 / 20)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 50), service_dist=DExp(1 / 10)),\n",
    "    Model(num_servers=3, queue_capacity=10, arrival_dist=DExp(1 / 20), service_dist=DExp(1 / 6)),\n",
    "   \n",
    "    #utilization = 0.5\n",
    "    Model(num_servers=1, queue_capacity=10, arrival_dist=DExp(1 / 40), service_dist=DExp(1 / 20)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 30), service_dist=DExp(1 / 30)),\n",
    "    Model(num_servers=3, queue_capacity=10, arrival_dist=DExp(1 / 24), service_dist=DExp(1 / 36)),\n",
    "   \n",
    "    #utilization = 0.9\n",
    "    Model(num_servers=1, queue_capacity=10, arrival_dist=DExp(1 / 60), service_dist=DExp(1 / 54)),\n",
    "    Model(num_servers=2, queue_capacity=10, arrival_dist=DExp(1 / 20), service_dist=DExp(1 / 36)),\n",
    "    Model(num_servers=3, queue_capacity=10, arrival_dist=DExp(1 / 10), service_dist=DExp(1 / 27))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Export\n",
    "\n",
    "Further analysis is performed in R, see `Report.Rmd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import json\n",
    "\n",
    "def compute_model(model_def):\n",
    "    m_idx, model = model_def\n",
    "    task_counts = [300] + list(range(10_000, 100_000, 5_000)) + list(range(100_000, 400_000, 100_000))\n",
    "    \n",
    "    print(f'Running model #{m_idx}')\n",
    "    results = [asdict(result) for result in simulate(model, task_counts)]\n",
    "    with open(f'model{m_idx}.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print(f'Saved {len(results)} results for model #{m_idx}')\n",
    "\n",
    "with open('models.json', 'w') as f:\n",
    "    json.dump(list(map(asdict, models)), f)\n",
    "\n",
    "with Pool(8) as pool:\n",
    "    pool.map(compute_model, enumerate(models))\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
