\documentclass[listings]{labreport}
\subject{Прикладная математкиа}
\titleparts{Лабораторная работа №1}{Информационный объем}
\students{Лабушев Тимофей}

\begin{document}

\maketitlepage

\section*{Цель работы}

Получить практические навыки решения задач на количественное измерение
информационного объема текстовой информации.

\section*{Задание}

\begin{enumerate}
\item Реализовать процедуру вычисления энтропии для текстового файла. В процедуре
необходимо подсчитывать частоты появления символов (прописные и заглавные буквы
не отличаются, знаки препинания рассматриваются как один символ, пробел является
самостоятельным символом), которые можно использовать как оценки вероятностей
появления символов. Затем вычислить величину энтропии. Точность вычисления --
4 знака после запятой. Обязательно предусмотреть возможность ввода имени файла,
для которого будет вычисляться энтропия;
\item Проверить запрограммированную процедуру на нескольких файлах
и заполнить таблицу 1 вычисленными значениями энтропии;
\item Вычислить значение энтропии для тех же файлов, но с использованием
частот вхождений пар символов и заполнить таблицу 2;
\item Проанализировать полученные результаты.
\end{enumerate}

\section*{Исходный код анализа текста}

\lstinputlisting[firstline=12, basicstyle=\scriptsize]{entropy/src/lib.rs}

\section*{Выводы}

В ходе работы было установлено, что вероятности встречи символов и пар символов
приблизительно равны для трех англоязычных текстов объемом 30, 50, 60 тысяч сиволов,
что объясняется их осмысленностью.

Стоит отметить и то, что значение энтропии для пар символов будет мешьше, 
так как вероятность нахождения пары ниже вероятности нахождения символа.

\end{document}
